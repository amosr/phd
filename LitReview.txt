=== au1997enlarging
Vector computers are good for flat data parallelism, which requires regular data, and so languages like Fortran only support rectangular array parallelism. Nested data parallelism can be converted to flat data parallelism with a /flattening/ transform. An extension to Fortran 90 is shown that flattens nested data parallelism, allowing existing optimising Fortran compilers to use the vector machinery.
ETC.

=== keller1998flattening
Problem: NESL etc flattening transform only supports homogenous vectors, so trees are awkward to program.
The flattening transform is extended to allow user-defined recursive types.

=== keller1999distributed
Separating local from global computations, so that fusion can be applied to only local computations.
--REREAD

=== chakravarty1999portable
NDP that works for vector/scalar, shared/distributed memory systems.

=== chakravarty2000more
Blelloch & Sabot's original flattening transformation didn't support general sum types, recursive types, or higher-order functions. Recursive types have been shown in \cite{keller1998flattening}.
This generalises flattening to support the full range of types in Haskell.
By formalising the flattening transformation in a lambda calculus they are able to easier express separate compilation.

=== chakravarty2001functional "Functional Array Fusion"
Fusion on unboxed arrays. Two combinators are used: loopP and replicateP.
loopP is a complicated loop that is a combination of filter, map, segmented fold, etc.
@replicateP n e@ simply creates an array of length @n@ full of elements @e@.
Rewrite rules are used to fuse adjacent loops and replicates; a loop over a replicate is
fused into a simple replicate of unit, since that is very cheap.

=== chakravarty2001nepal "Nepal - Nested Data-Parallelism in Haskell"


=== barnes1986hierarchical
Distribute N-body problem into a heirarchical octree, allowing n log n instead of n^2 interactions.
Existing hierarchical N-body simulations exist (Appel, Jernigan, Porter) but the loss in accuracy is hard to analyse. Is this because the tree structure is not necessarily a space partitioning?
A better idea of where the accuracy errors are is possible because the octree is an up-to-date space partitioning.

=== barnes1990modified
A modification of Barnes-Hut that is better for vector machines. By sharing some of the 'interaction list' between nearby particles.
Meh.


=== peyton2007call
SpecConstr is an optimisation that specialises recursive functions to remove unnecessary allocation and pattern-matching of constructors.
When a recursive function pattern matches or destructs one of its arguments and makes a recursive call with a constructor of that argument,
the recursive call can be specialised for that particular argument so no allocation or unboxing is necessary.
This is done in three stages;
 1. Identify the call patterns: recursive function call, with at least one argument being a constructor application that is pattern-matched elsewhere in the body.
 2. Specialise: the function is copied and simplified for the case of that particular constructor argument
 3. Propagate: the existing rewrite rule system is used to find any calls to the functions with known constructors as arguments, and rewritten to call the specialised version.
Additional refinements are used to decide which functions to specialise. This is a trade-off between runtime efficiency and code explosion:
 1. take into account variables that have been let-bound or pattern matches, when used as arguments
 2. record nested pattern matches
 3. when specialising a function, collect new patterns from the specialised right-hand side
 4. mutual recursion
There is a potential problem with reboxing: when an argument may be specialised but is used as an argument to another function, specialisation may perform more allocation.


=== blelloch1989scans
If distributed vector machines implemented scan operations on vectors, much time could be saved that would otherwise be spent waiting for memory accesses to return.
Explanation of radix sort example.
Segmented scan operations use a vector of flags the same length as the values. I guess this totally disallows empty segments, which makes sense. True flag indicates the start of a segment. What happens if there is no True flag at the start..?
Clever implementation of Quicksort using segmented scans and iteratively splitting each segment into more subsegments. Using the segment flag representation allows very easy splitting.
It seems quite disingenuous to claim ``constant time for a vector of size n, provided there are n nodes in the machine''. It does deal with this eventually though, in the load-balancing section.
Hardware description of a tree scan.

=== blelloch1990vector
Book covering scan primitives and basic vectorisation/flattening.
Must reread this to understand the flattening they use.

=== blelloch1991comparison
Different sorting algorithms are implemented and compared for the connection machine. Irrelevant.

=== blelloch1993implementation
Goes through the implementation of NESL, but only the VCODE (virtual machine) and CVL (parallel primitives library).
Doesn't actually talk about flattening or vectorisation.
Irrelevant.

=== blelloch1995nesl
This is more like a user guide / tutorial for programming in NESL, rather than any information about how it is implemented.

=== blelloch1996programming
More example programs in NESL...


=== thiemann1993avoiding "Avoiding repeated tests in pattern matching"
Very similar to SpecConstr, except for a strict functional language.
Really there's no difference that it's strict.
Explains semantics of a small first-order subset of ML and then shows implementation of specialisation.
First an environment is built up of call patterns of recursive calls, then those cases are specialised.

=== burstall1977transformation "A transformation system for developing recursive programs"
Very interesting system of unfolding and then folding recursive definitions.
With some cleverness they are able to rewrite several recursive calls into a single recursion.
Seems reminiscent of tupling.
However, it seems to require user intervention and relies on domain knowledge such as commutativity of addition.


=== stephens1997survey "A survey of stream processing"
Stream processing systems can be thought of as a directed graph,
but provides a more rigorous formal definition.
Goes through many languages showing their primitive operations and
implementing a flip-flop in each. 
Many variations. Many references to other papers.

=== bechet1994limix "Limix: a partial evaluator for partially static structures"
Splits function specialisation from dead-variable elimination.
This solves a problem with nested structures that ``standard specialisers'' apparently do not treat.
May be some relation to the `reallocation problem' we have in GHC, but I'm not certain about that.


=== scholz1998defining
Single assignment C with special loop operation.
Not really sure.

=== johnston2004advances "Advances in Dataflow Programming Languages"
Broad overview of different dataflow based languages.
Originally targetting dataflow computers but also von Neumann. Eh.

=== wang2013loop "Loop scheduling with memory access reduction subject to register constraints for DSP applications"
Quite low-level, working on assembly language.
Reduce memory accesses in cases where a specific array element is used in successive iterations.
  for (int i =...)
    k[i] = k[i] * k[i+1];
The memory access for k[i+1] should be stored in a register and kept for the next iteration's k[i].
Build a DAG out of loop body (with no loop ??), then create a memory access graph (MAG) to describe the memory dependence of operations over successive iterations.
After the MAG is created, a register usage scheduling is created and used to decide which registers to use.


== TODO: find

Chatterjee -- maybe not
Sabot


== TODO?books
Neil D. Jones. Partial Evaluation and Automatic Program Generation. 1993

